{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DataFrame\n",
    "import pandas as pd\n",
    "data = {'boiler_case_tmp': [30.25],\n",
    "        'is_boiler_on': [None]}\n",
    "\n",
    "index = pd.to_datetime(['2024-03-11 17:00:00+00:00'])\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "# get value of boiler_case_tmp\n",
    "is_boiler_on = df['is_boiler_on'].values[0]\n",
    "print(type(is_boiler_on))\n",
    "print(str(is_boiler_on))\n",
    "if is_boiler_on is None:\n",
    "        print('is_boiler_on is None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0 < 1:\n",
    "    e = 2\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing /Users/adamgrunwald/Desktop/FIT/smart_boiler/smartboiler/src/smartboiler/data_handler.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamgrunwald/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing /Users/adamgrunwald/Desktop/FIT/smart_boiler/smartboiler/src/smartboiler/forecast.py\n",
      "Importing /Users/adamgrunwald/Library/Python/3.9/lib/python/site-packages/smartboiler/__init__.py\n",
      "Importing /Users/adamgrunwald/Library/Python/3.9/lib/python/site-packages/smartboiler/data_handler.py\n"
     ]
    }
   ],
   "source": [
    "from data_handler import DataHandler\n",
    "from forecast import Forecast\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataHandler = DataHandler(\n",
    "influx_id=\"localhost\",\n",
    "db_name=\"smart_home_zukalovi\",\n",
    "db_username=\"root\",\n",
    "db_password=\"root\",\n",
    "relay_entity_id=\"shelly1pm_84cca8b07eae\",\n",
    "relay_power_entity_id=\"shelly1pm_84cca8b07eae_power\",\n",
    "tmp_boiler_case_entity_id=\"esphome_web_c771e8_tmp3\",\n",
    "tmp_output_water_entity_id=\"esphome_web_c771e8_ntc_temperature_b_constant_2\",\n",
    "start_of_data=datetime(2023, 11, 1, 0, 0, 0, 0))\n",
    "left = datetime(2024,1,1,8,0,0)\n",
    "right = datetime(2024,1,5,19,0,0)\n",
    "data = dataHandler.get_actual_boiler_stats(group_by_time_interval=\"10m\",limit=300, left_time_interval=left, right_time_interval=right)\n",
    "data_for_prediction = dataHandler.get_data_for_prediction(left_time_interval=left, right_time_interval=right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast import Forecast\n",
    "from datetime import datetime\n",
    "start_of_data = datetime(2024, 1, 1, 0, 0, 0, 0)\n",
    "forecast = Forecast(dataHandler,start_of_data=start_of_data, model_path='lstm_model_zukalovi.h5')\n",
    "forecast.load_model(left_time_interval=start_of_data, right_time_interval=datetime(2024,1,2,8,0,0))\n",
    "start_of_forecast = datetime(2023,12,31, 8, 0, 0, 0)\n",
    "end_of_forecast = datetime(2024, 1, 1, 0, 0, 0, 0)\n",
    "next_steps = forecast.get_forecast_next_steps(left_time_interval=start_of_forecast, right_time_interval=end_of_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'measurement': 'prediction', 'time': '2024-03-13T22:16:54Z', 'fields': {'0': 0.03746350882661484, '1': 0.038517255848736776, '2': 0.03697460355435654, '3': 0.03748908825301396, '4': 0.03586107435453263, '5': 0.03693181193419978, '6': 0.035859717531164945, '7': 0.03706897122488788, '8': 0.03625852954556017, '9': 0.03747892092457994, '10': 0.036666468688182345, '11': 0.03744066167184289}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "write_json = dataHandler.write_forecast_to_influxdb(next_steps, 'predictions_longtime_mean')\n",
    "\n",
    "sql_query = f'SELECT * FROM \"smart_home_zukalovi\".\"autogen\".\"prediction\" '\n",
    "result = dataHandler.dataframe_client.query(sql_query)[\n",
    "    'prediction']\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  0         1        10        11         2  \\\n",
      "2024-03-13 22:13:17+00:00  0.037464  0.038517  0.036666  0.037441  0.036975   \n",
      "2024-03-13 22:16:54+00:00  0.037464  0.038517  0.036666  0.037441  0.036975   \n",
      "\n",
      "                                  3         4         5        6         7  \\\n",
      "2024-03-13 22:13:17+00:00  0.037489  0.035861  0.036932  0.03586  0.037069   \n",
      "2024-03-13 22:16:54+00:00  0.037489  0.035861  0.036932  0.03586  0.037069   \n",
      "\n",
      "                                  8         9  \n",
      "2024-03-13 22:13:17+00:00  0.036259  0.037479  \n",
      "2024-03-13 22:16:54+00:00  0.036259  0.037479  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next_steps)\n",
    "from boiler import Boiler\n",
    "boiler = Boiler(\n",
    "    base_url='fsd',\n",
    "    token='dfs',\n",
    "    headers='fsd',\n",
    "    boiler_switch_entity_id='dwe',\n",
    "    dataHandler=dataHandler,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,7):\n",
    "    df = boiler.high_tarif_schedule[boiler.high_tarif_schedule['weekday']==i]\n",
    "    df.plot(x='time', y='unavailable_minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boiler.is_needed_to_heat(tmp_act=55, prediction_of_consumption= next_steps\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient, DataFrameClient\n",
    "\n",
    "dataHandlerForm = DataHandler(influx_id=\"localhost\",\n",
    "db_name=\"smart_home_formankovi\",\n",
    "db_username=\"root\",\n",
    "db_password=\"root\",\n",
    "relay_entity_id=\"shelly1pm_34945475a969\",\n",
    "relay_power_entity_id=\"shelly1pm_84cca8b07eae_power\",\n",
    "tmp_boiler_case_entity_id=\"shelly1pm_34945475a969_temperature_2\",\n",
    "tmp_output_water_entity_id=\"esphome_boiler_temps_ntc_temperature_b_constant\",\n",
    "start_of_data=datetime(2023, 11, 1, 0, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_form = dataHandlerForm.get_data_for_training_model()\n",
    "# save as pkl\n",
    "import pickle\n",
    "with open('train_form_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_form, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zuka = dataHandler.get_data_for_training_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pkl\n",
    "import pickle\n",
    "with open('train_zuka_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_zuka, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import ylim\n",
    "\n",
    "\n",
    "data_for_prediction.plot(y='longtime_mean', kind='line', ylim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast import Forecast\n",
    "from datetime import datetime\n",
    "start_of_data = datetime(2024, 1, 1, 0, 0, 0, 0)\n",
    "forecast = Forecast(dataHandler,start_of_data=start_of_data, model_path='lstm_model_zukalovi.h5')\n",
    "forecast.load_model(left_time_interval=start_of_data, right_time_interval=datetime(2024,1,2,8,0,0))\n",
    "start_of_forecast = datetime(2023,12,31, 8, 0, 0, 0)\n",
    "end_of_forecast = datetime(2024, 1, 1, 0, 0, 0, 0)\n",
    "next_steps = forecast.get_forecast_next_steps(left_time_interval=start_of_forecast, right_time_interval=end_of_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "next_steps.plot(y='longtime_mean', ylim=0, kind='line')\n",
    "vals = next_steps['longtime_mean']\n",
    "# create a dict with the values and index as key\n",
    "vals = vals.to_dict()\n",
    "print(vals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = forecast.generator(dataframe = forecast.df_train_norm, \n",
    "                     target_name = 'longtime_mean', \n",
    "                     lookback = forecast.lookback,\n",
    "                     delay = forecast.delay,\n",
    "                     min_index = 0,\n",
    "                     max_index = None,\n",
    "                     step = 1,\n",
    "                     shuffle = False,\n",
    "                     batch_size = forecast.df_train_norm.shape[0])\n",
    "(X, y_truth) = next(test_gen)\n",
    "y_pred = forecast.model.predict(X)\n",
    "\n",
    "(X, y_truth) = next(test_gen)\n",
    "\n",
    "y_pred = forecast.model.predict(X)\n",
    "\n",
    "np.expand_dims(y_truth,axis=1).shape\n",
    "y_pred = np.concatenate((y_pred,np.zeros((y_pred.shape[0],forecast.num_of_features))),axis=1)\n",
    "y_pred = forecast.scaler.inverse_transform(y_pred)\n",
    "y_pred = y_pred[:,0]\n",
    "\n",
    "y_truth = np.concatenate((np.expand_dims(y_truth,axis=1),np.zeros((y_truth.shape[0],forecast.num_of_features))),axis=1)\n",
    "y_truth = forecast.scaler.inverse_transform(y_truth)\n",
    "y_truth = y_truth[:,0]\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# plot y_pred and y_truth\n",
    "plt.plot(y_pred[-500:], label='y_pred')\n",
    "plt.plot(y_truth[-500:], label='y_truth')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x=y_pred,y=y_truth)\n",
    "mse = mean_squared_error(y_true=y_truth, y_pred=y_pred, squared=True)\n",
    "rmse = mean_squared_error(y_true=y_truth, y_pred=y_pred, squared=False)\n",
    "\n",
    "\n",
    "print('R2 = ',r_value*r_value)\n",
    "print('mse = ',mse)\n",
    "print('rmse = ',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = forecast.generator(dataframe = forecast.df_train_norm, \n",
    "                     target_name = 'longtime_mean', \n",
    "                     lookback = forecast.lookback,\n",
    "                     delay = forecast.delay,\n",
    "                     min_index = 0,\n",
    "                     max_index = None,\n",
    "                     step = 1,\n",
    "                     shuffle = False,\n",
    "                     batch_size = forecast.df_train_norm.shape[0])\n",
    "(X, y_truth) = next(test_gen)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "(X, y_truth) = next(test_gen)\n",
    "\n",
    "y_pred = forecast.model.predict(X)\n",
    "\n",
    "np.expand_dims(y_truth,axis=1).shape\n",
    "y_pred = np.concatenate((y_pred,np.zeros((y_pred.shape[0],forecast.num_of_features))),axis=1)\n",
    "y_pred = forecast.scaler.inverse_transform(y_pred)\n",
    "y_pred = y_pred[:,0]\n",
    "\n",
    "y_truth = np.concatenate((np.expand_dims(y_truth,axis=1),np.zeros((y_truth.shape[0],forecast.num_of_features))),axis=1)\n",
    "y_truth = forecast.scaler.inverse_transform(y_truth)\n",
    "y_truth = y_truth[:,0]\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# plot y_pred and y_truth\n",
    "plt.plot(y_pred[-500:], label='y_pred')\n",
    "plt.plot(y_truth[-500:], label='y_truth')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x=y_pred,y=y_truth)\n",
    "mse = mean_squared_error(y_true=y_truth, y_pred=y_pred, squared=True)\n",
    "rmse = mean_squared_error(y_true=y_truth, y_pred=y_pred, squared=False)\n",
    "\n",
    "\n",
    "print('R2 = ',r_value*r_value)\n",
    "print('mse = ',mse)\n",
    "print('rmse = ',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_steps = forecast.get_forecast_next_steps(left_time_interval=datetime(2024,2,27,0,0,0),right_time_interval=datetime(2024, 3, 1, 0, 0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(next_steps['longtime_mean'], label='next_steps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with column datetime from now to now+6hours and rows by 30 minutes\n",
    "\n",
    "forecast_begin_date = datetime(2024, 1, 1, 0, 0, 0) \n",
    "forecast_end_date = datetime(2024, 1, 4, 23, 59, 59)\n",
    "\n",
    "df_predict = pd.DataFrame({'datetime': pd.date_range(forecast_begin_date, forecast_end_date, freq='30min')})\n",
    "df_predict['longtime_mean'] = 0\n",
    "df_predict['weekday_sin'] = np.sin(2 * np.pi * df_predict['datetime'].dt.weekday / 7)\n",
    "df_predict['weekday_cos'] = np.cos(2 * np.pi * df_predict['datetime'].dt.weekday / 7)\n",
    "df_predict['hour_sin'] = np.sin(2 * np.pi * df_predict['datetime'].dt.hour / 24)\n",
    "df_predict['hour_cos'] = np.cos(2 * np.pi * df_predict['datetime'].dt.hour / 24)\n",
    "df_predict['minute_sin'] = np.sin(2 * np.pi * df_predict['datetime'].dt.minute / 60)\n",
    "df_predict['minute_cos'] = np.cos(2 * np.pi * df_predict['datetime'].dt.minute / 60)\n",
    "# delete column datetime\n",
    "df_predict = df_predict.drop(columns='datetime')\n",
    "df_predict_trans = df_predict.copy()\n",
    "df_predict_trans[df_predict.columns] = forecast.scaler.transform(df_predict)\n",
    "\n",
    "predict_gen = forecast.generator(df_predict_trans, 'longtime_mean', \n",
    "                lookback = forecast.lookback,\n",
    "                delay = forecast.delay,\n",
    "                min_index = 0,\n",
    "                max_index = None,\n",
    "                step = 1,\n",
    "                shuffle = False,\n",
    "                batch_size = df_predict.shape[0])\n",
    "\n",
    "(X_2, y_2) = next(predict_gen)\n",
    "print((X_2.shape))\n",
    "y_pred_2 = forecast.model.predict(X_2)\n",
    "y_pred_2_inv = np.concatenate((y_pred_2,np.zeros((y_pred_2.shape[0],forecast.num_of_features))),axis=1)\n",
    "y_pred_2_inv = forecast.scaler.inverse_transform(y_pred_2_inv)\n",
    "y_pred_2_inv = y_pred_2_inv[:,0]\n",
    "\n",
    "plt.plot(y_pred_2_inv, color = 'green', label = 'Predicted data')\n",
    "plt.plot(y_2, color = 'green', label = 'Predicted data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df with datetime and predicted values\n",
    "df_predicted = pd.DataFrame()\n",
    "df_predicted['longtime_mean'] = y_pred_2\n",
    "print(len(y_pred_2))\n",
    "forecast_begin_date = forecast_begin_date + pd.Timedelta(5, unit='h')\n",
    "x = pd.date_range(forecast_begin_date , forecast_end_date, freq='30min')\n",
    "print(x.shape)\n",
    "df_predicted['datetime'] = pd.date_range(forecast_begin_date , forecast_end_date, freq='30min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "            \"water_flow\": {\n",
    "                \"sql_query\": f'SELECT mean(\"value\") AS \"water_flow_L_per_hour_mean\" FROM \"smart_home_zukalovi\".\"autogen\".\"L/min\" GROUP BY time(5s) FILL(0)',\n",
    "                \"measurement\": \"L/min\",\n",
    "            },\n",
    "            \"water_temperature\": {\n",
    "                \"sql_query\": f'SELECT mean(\"value\") AS \"water_temperature_mean\" FROM \"smart_home_zukalovi\".\"autogen\".\"°C\" WHERE \"entity_id\"=\\'esphome_web_c771e8_ntc_temperature_b_constant_2\\' GROUP BY time(5s) FILL(previous)',\n",
    "                \"measurement\": \"°C\",},\n",
    "            \"boiler_wattage\": {\n",
    "                \"sql_query\": f'SELECT mean(\"value\") AS \"boiler_wattage_mean\" FROM \"smart_home_zukalovi\".\"autogen\".\"W\" WHERE \"entity_id\"=\\'shelly1pm_84cca8b07eae_power\\' GROUP BY time(5s) FILL(0)',\n",
    "                \"measurement\": \"W\",\n",
    "            },\n",
    "            }\n",
    "            # \"boiler_relay_status\": {\"sql_query\": f'SELECT last(\"value\") AS \"boiler_relay_status\" FROM \"smart_home_formankovi\".\"autogen\".\"state\" WHERE time > {time_interval_left} AND time < {time_interval_right} AND \"entity_id\"=\\'{self.relay_entity_id}\\' GROUP BY time(1h) FILL(previous)',\n",
    "            #                        \"measurement\": \"state\"},\n",
    "        \n",
    "from influxdb import DataFrameClient\n",
    "dataframe_client = DataFrameClient(\n",
    "            host='localhost',\n",
    "            port=8086,\n",
    "            username='root',\n",
    "            password='root',\n",
    "            database='smart_home_zukalovi'\n",
    "        )\n",
    "\n",
    "df_all_list = []\n",
    "# iterate over key an value in data_formankovi\n",
    "for key, value in queries.items():\n",
    "    # get data from influxdb\n",
    "    result = dataframe_client.query(value[\"sql_query\"])[\n",
    "        value[\"measurement\"]\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(result)\n",
    "    df_all_list.append(df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_all_list, axis=1)\n",
    "df = df[['water_flow_L_per_hour_mean', 'water_temperature_mean', 'boiler_wattage_mean']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df = pd.concat(df_all_list, axis=1)\n",
    "df = df[['water_flow_L_per_hour_mean', 'water_temperature_mean', 'boiler_wattage_mean']]\n",
    "df['water_flow_L_per_hour_mean'] = df['water_flow_L_per_hour_mean']\n",
    "\n",
    "df = df.resample('1min').mean()\n",
    "df[f\"consumed_heat_kJ\"] = (\n",
    "            df[f\"water_flow_L_per_hour_mean\"]\n",
    "            * (df[f\"water_temperature_mean\"] - 10)\n",
    "            * 4.186\n",
    "            * 0.5\n",
    "            \n",
    "            \n",
    "        )\n",
    "df['boiler_wattage_kWh'] = df['boiler_wattage_mean'] / (1000*60)\n",
    "df = df.groupby(pd.Grouper(freq='7D'))\n",
    "df = df.agg({'consumed_heat_kJ': 'sum', 'water_flow_L_per_hour_mean': 'mean', 'water_temperature_mean': 'mean', 'boiler_wattage_kWh': 'sum'})\n",
    "        \n",
    "# df consumed_heat_kJ to kWh\n",
    "df[f\"consumed_heat_kWh\"] = df[f\"consumed_heat_kJ\"] / (3600)\n",
    "df[f\"consumed_heat_kWh\"] += 0.4*7\n",
    "print(df)\n",
    "\n",
    "df['heat_loss'] = df['consumed_heat_kWh'] - df['boiler_wattage_kWh']\n",
    "\n",
    "plt.plot( df['boiler_wattage_kWh'], label=\"boiler_heat_kWh\")\n",
    "plt.plot( df['consumed_heat_kWh'], label=\"consumed_heat_kWh\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12, 0, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pytz import utc\n",
    "from data_handler import DataHandler\n",
    "from forecast import Forecast\n",
    "from datetime import datetime, timedelta\n",
    "start_of_data = datetime(2023, 11, 1)\n",
    "end_of_training_data = datetime(2024, 1, 5)\n",
    "dataHandler = DataHandler(\n",
    "    \"localhost\",\n",
    "    \"smart_home_zukalovi\",\n",
    "    \"root\",\n",
    "    \"root\",\n",
    "    \"shelly1pm_84cca8b07eae\",\n",
    "    \"shelly1pm_84cca8b07eae_power\",\n",
    "    \"esphome_web_c771e8_tmp3\",\n",
    "    \"esphome_web_c771e8_ntc_temperature_b_constant_2\",\n",
    "start_of_data,\n",
    ")\n",
    "\n",
    "forecast = Forecast(dataHandler, start_of_data=start_of_data, model_path='lstm_model_zukalovi.h5')\n",
    "forecast.train_model(begin_of_training=start_of_data, end_of_training=end_of_training_data)\n",
    "forecast.build_model()\n",
    "forecast.fit_model()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import le\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "forecast_begin_date = datetime(2024, 1, 4, 0, 0, 0)\n",
    "forecast_end_date = datetime(2024, 1, 1, 23, 59, 59)\n",
    "queries = dataHandler.get_database_queries(\n",
    "    left_time_interval=forecast_begin_date - timedelta(hours=48),\n",
    "    right_time_interval=forecast_begin_date,\n",
    ")\n",
    "df_all = dataHandler.get_df_from_queries(queries)\n",
    "df_all = dataHandler.process_kWh_water_consumption(df_all)\n",
    "df_all.index = df_all.index.tz_localize(None)\n",
    "df_all, _ = dataHandler.transform_data_for_ml(df_all, predicted_column=\"longtime_mean\")\n",
    "df_all_copy = df_all.copy()\n",
    "forecast_future = pd.DataFrame()\n",
    "\n",
    "current_forecast_begin_date = forecast_begin_date\n",
    "current_forecast_end_date = forecast_begin_date + timedelta(minutes=30)\n",
    "for i in range(0, 48):\n",
    "    print(\"-----\")\n",
    "\n",
    "    df_predict = pd.DataFrame(\n",
    "        {\n",
    "            \"datetime\": pd.date_range(\n",
    "                current_forecast_begin_date, current_forecast_end_date, freq=\"30min\"\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    df_predict[\"longtime_mean\"] = 0\n",
    "    df_predict[\"weekday_sin\"] = np.sin(\n",
    "        2 * np.pi * df_predict[\"datetime\"].dt.weekday / 7\n",
    "    )\n",
    "    df_predict[\"weekday_cos\"] = np.cos(\n",
    "        2 * np.pi * df_predict[\"datetime\"].dt.weekday / 7\n",
    "    )\n",
    "    df_predict[\"hour_sin\"] = np.sin(2 * np.pi * df_predict[\"datetime\"].dt.hour / 24)\n",
    "    df_predict[\"hour_cos\"] = np.cos(2 * np.pi * df_predict[\"datetime\"].dt.hour / 24)\n",
    "    df_predict[\"minute_sin\"] = np.sin(2 * np.pi * df_predict[\"datetime\"].dt.minute / 60)\n",
    "    df_predict[\"minute_cos\"] = np.cos(2 * np.pi * df_predict[\"datetime\"].dt.minute / 60)\n",
    "    # delete column datetime\n",
    "    df_predict = df_predict.drop(columns=\"datetime\")\n",
    "    len_df_predict = df_predict.shape[0]\n",
    "\n",
    "    # concar df_all and df_predict\n",
    "\n",
    "    df_all = pd.concat([df_all, df_predict], axis=0)\n",
    "    df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "    df_predict_norm = df_all.copy()\n",
    "    df_predict_norm[df_all.columns] = forecast.scaler.transform(df_all)\n",
    "    # create predict df with values\n",
    "\n",
    "    predict_gen = forecast.generator(\n",
    "        dataframe=df_predict_norm,\n",
    "        target_name=forecast.predicted_column,\n",
    "        lookback=forecast.lookback,\n",
    "        delay=forecast.delay,\n",
    "        min_index=0,\n",
    "        max_index=None,\n",
    "        step=1,\n",
    "        shuffle=False,\n",
    "        batch_size=df_predict.shape[0],\n",
    "    )\n",
    "\n",
    "    (X, y_truth) = next(predict_gen)\n",
    "\n",
    "    y_pred = forecast.model.predict(X)\n",
    "\n",
    "    # np.expand_dims(y_truth,axis=1).shape\n",
    "    y_pred_inv = np.concatenate(\n",
    "        (y_pred, np.zeros((y_pred.shape[0], forecast.num_of_features))), axis=1\n",
    "    )\n",
    "    y_pred_inv = forecast.scaler.inverse_transform(y_pred_inv)\n",
    "    y_pred_inv = y_pred_inv[:, 0]\n",
    "    # set df_all last len_df_predict values to y_pred_inv\n",
    "    df_all.iloc[-len_df_predict:, df_all.columns.get_loc(\"longtime_mean\")] = y_pred_inv\n",
    "    # plt.plot(df_all.iloc[-len_df_predict:, df_all.columns.get_loc('longtime_mean')], color = 'green', label = 'Predicted data')\n",
    "    df_all = df_all[len_df_predict:]\n",
    "    forecast_future = pd.concat([forecast_future, df_all[-len_df_predict:]], axis=0)\n",
    "    forecast_future = forecast_future.reset_index(drop=True)\n",
    "\n",
    "    current_forecast_begin_date = current_forecast_begin_date + timedelta(hours=1)\n",
    "    current_forecast_end_date = current_forecast_end_date + timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_future.plot(y='longtime_mean', label='longtime_mean')\n",
    "df_all_copy[-96:].plot(y='longtime_mean', label='longtime_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataHandler.write_forecast_to_influxdb(forecast_future, 'consumption_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_all_copy['longtime_mean'].values\n",
    "#add forecast_future to test\n",
    "test = np.concatenate((test,forecast_future['longtime_mean'].values),axis=0)\n",
    "\n",
    "plt.plot(df_all_copy['longtime_mean'], color = 'blue', label = 'Predicted data')\n",
    "plt.plot(test[len(df_all_copy):], color = 'red', label = 'Predicted data', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save forecast.model\n",
    "from matplotlib.pyplot import step\n",
    "from tensorflow.keras.models import Sequential \n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "from keras.layers import LSTM\n",
    "model_path = 'forecast_model'\n",
    "# Create a basic model instance\n",
    "model = Sequential()\n",
    "model.add(tf.keras.Input(shape=(None, forecast.df_train_norm.shape[1])))\n",
    "model.add(tf.keras.layers.Conv1D(filters=6, kernel_size=5, activation='relu'))\n",
    "model.add(LSTM(6, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(6, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam',metrics=[forecast.r2_keras])\n",
    "test_data = forecast.df_train_norm.head(1000)\n",
    "test_gen = forecast.generator(dataframe = test_data, \n",
    "                target_name = forecast.predicted_column, \n",
    "                lookback = forecast.lookback,\n",
    "                delay = forecast.delay,\n",
    "                min_index = 0,\n",
    "                max_index = int(test_data.shape[0]*0.8),\n",
    "                step = 1,\n",
    "                shuffle = True,\n",
    "                batch_size = forecast.batch_size)\n",
    "# Evaluate the model\n",
    "steps = int((test_data.shape[0]*0.9 - forecast.lookback) // forecast.batch_size)\n",
    "\n",
    "loss, acc = model.evaluate(forecast.train_gen, verbose=1, steps=steps)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "model.load_weights('lstm_model.h5')\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(forecast.train_gen, verbose=1, steps=steps)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forecast_future['longtime_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(forecast_future['consumed_heat_kWh'], label=\"Predicted\")\n",
    "\n",
    "begin = datetime(2024, 1, 1, 0, 0, 0) \n",
    "end = datetime(2024, 1, 1, 23, 59, 59)\n",
    "\n",
    "queries = dataHandler.get_database_queries(left_time_interval=begin - timedelta(days=1), right_time_interval=begin)\n",
    "df_all = dataHandler.get_df_from_queries(queries)\n",
    "df_all = dataHandler.process_kWh_water_consumption(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_all, _= dataHandler.transform_data_for_ml(df_all, predicted_column='longtime_mean')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "df_predict_norm = df_all.copy()\n",
    "df_predict_norm[df_predict_norm.columns] = forecast.scaler.transform(df_all)\n",
    "# create predict df with values \n",
    "\n",
    "predict_gen = forecast.generator(dataframe = df_predict_norm, \n",
    "        target_name = forecast.predicted_column, \n",
    "        lookback = forecast.lookback,\n",
    "        delay = forecast.delay,\n",
    "        min_index = 0,\n",
    "        max_index = None,\n",
    "        step = 1,\n",
    "        shuffle = False,\n",
    "        batch_size = df_predict_norm.shape[0])\n",
    "\n",
    "(X, y_truth) = next(predict_gen)\n",
    "\n",
    "y_pred = forecast.model.predict(X)\n",
    "\n",
    "# np.expand_dims(y_truth,axis=1).shape\n",
    "y_pred_inv = np.concatenate((y_pred,np.zeros((y_pred.shape[0],forecast.num_of_features))),axis=1)\n",
    "y_pred_inv = forecast.scaler.inverse_transform(y_pred_inv)\n",
    "y_pred_inv = y_pred_inv[:,0]\n",
    "\n",
    "y_truth_inv = np.concatenate((np.expand_dims(y_truth,axis=1),np.zeros((y_truth.shape[0],forecast.num_of_features))),axis=1)\n",
    "y_truth_inv = forecast.scaler.inverse_transform(y_truth_inv)\n",
    "y_truth_inv = y_truth_inv[:,0]\n",
    "\n",
    "statistics = {}\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x=y_pred_inv,y=y_truth_inv)\n",
    "mse = mean_squared_error(y_true=y_truth_inv, y_pred=y_pred_inv, squared=True)\n",
    "rmse = mean_squared_error(y_true=y_truth_inv, y_pred=y_pred_inv, squared=False)\n",
    "\n",
    "statistics['slope'] = slope\n",
    "statistics['intercept'] = intercept\n",
    "statistics['r_value'] = r_value\n",
    "statistics['p_value'] = p_value\n",
    "statistics['std_err'] = std_err\n",
    "statistics['mse'] = mse\n",
    "statistics['rmse'] = rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyparsing import col\n",
    "plt.plot(y_pred_inv, label=\"Predicted\")\n",
    "plt.plot(y_truth_inv, label=\"True\", color='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boiler_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
